#### The idea of AGI
The concept of "general intelligence" refers to the capacity for efficient cross-domain optimization.

Some operational definitions include:
* The Turing Test: no exact conditions until now
* The Coffee Test: go into an average house and figure out how to make coffee
* The Robot College Student Test: enroll in a human university and get its degree
* The Employment Test: have at least the potential to completely automate economically important jobs

note: <span style = "color:red">Here the author admitted that no single human can pass the employment test because no one is competent to any jobs only if they have enough time to train themselves before the test. However, the author thought AGI had near-perfect memory, faster thinking speed and no need for sleep. I am confused about this optimistic idea. How can we make sure that the future AGI have no need for sleep? If the general intelligence can only be achieved by the complex interaction among some dynamic parts and these parts need time to evolve, the AGI will need time to "sleep" like humans.</span>

### AGI: narrow and general intelligence
Most of the current AI have only narrow intelligence. They are trained with task-based approach so they can only solve a small range of tasks. While humans have some important basic skills like cognitive skills making them able to learn how to process difficult tasks. This is called the generalisation-based apporach. (<span style = "color: purple">Maybe these skills can be obtained by placing the AI in a complex world and they have to deal with heterogeneous situations.</span>)

If we have AGI, there are three factors could acclerate the emergence of superintelligence:
* replication
* cultural learning (AGI can learn cooperatively by communication)
* recursive improvement

### Three Imapcts of Machine Intelligence
* Growth will accelerate: automating tech progress leads to fast growth, substituting captial for labor leads to fast growth, extrapolating the historical record suggests fast growth
* Wages will fall
* Human values won't be the only things shaping the future

### The Bitter Lesson
<span style = "color: red">Search</span> and <span style = "color: red">learning</span> are the two most important classes of techniques for utilizing massive amount of computation. General methods that leverage computation are ultimately the most effecive.

note: The outside world is intrinsically complex. Since AI can learn and search faster than us due to its computation ability, we should built them in the way that embedding the methods we used to discover not embedding what we have discovered.

### Reframing Superintelligence
How AI progresses currently?
* AI researchers consider a problem
* define a serach space
* formulate an objective
* use an optimization technique in order to obtain an AI system

A service is a AI created for carrying out specific tasks. The comprehensive AI services (CAIS) is the collection of services that can perform any task(for example, the collection contains a service-cretating-service which can train a new AI system or combine existing AI systems for a new task). Even before we can make a monolithic AGI agent, CAIS can be a analog of AGI.

CAIS is not dangerous like AGI because of two reasons:
* That a system consists of VNM rational modules doesn't means itself is VNM rational.
* We can define the channels of communication clearly to make sure the systme is interpretable and transparent.

I agree with the idea that a true AGI will outperform any CAIS because we have no knowledge about the structure of AGI. It is unlikely that we can construct a system with many different parts and they can function like a whole just like what happened in computer vision problems. When we try to divide the problem into several sub-problems, the performance is worse than an end-to-end NN.

We can leverage the services from CAIS to make the AGI safe. (<span style = "color: purple">But if it is proved that AGI outperforms CAIS dramatically, the helpness CAIS can give us will be much smaller.</span>)

However, CAIS can also be dangerous just because some systems can take high impact actions.

### Prosaic AI Alignment
Prosaic AGI means AGI we can implemented with existing methods without any deeper understanding of the intelligence. For example, if AGI can be realized by larger deep neural networks trained with more data, it is a prosaic AGI.

The probability of existence of prosaic AGI means we may have no methods to align AGI even when they become true. In that case, we should think about practical ways for AI alignment from now. Because we can learn a lot from the alignment of prosaic AGI, we can first development alignment methods which can help us deal with DNN or RL agents.